{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3948349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992d4a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87731919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ef875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \" I will be a data scientist one day.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9521115",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizes_text = word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c4bfaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'will', 'be', 'a', 'data', 'scientist', 'one', 'day', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizes_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17dea9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60498393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd71690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"The word Mother is a very pious word and whosoever is called by the name ‘Mother’ is a person who sacrifices and\n",
    "            prioritizes her children over anything. Her whole Life revolves around the well-being of her child, their growth, \n",
    "            their development, and their welfare. A Mother not just only gives birth to a child but she takes a Lifelong \n",
    "            commitment to take care of her child. \n",
    "\n",
    "            The only unconditional love in the world is the mother's love. My mother is my inspiration, my superhero, my best \n",
    "            friend, and my guiding light. My life would not have been beautiful without my mother. Through ups and downs and in\n",
    "            every step of life, she holds my hand and supports and encourages me. No matter what happens, my mother is always \n",
    "            there beside me- cheering me up and motivating me. All mothers in the world are great and so, we should not \n",
    "            celebrate their contribution in our life on Mother's Day only, which is 10th May, but every day of the year and \n",
    "            throughout their life. It is because no gesture of appreciation is ever enough when it comes to acknowledging our \n",
    "            mother. Her selfless love and sacrifice are the precious of all gifts under the sun.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d920fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_para = sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c037dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The word Mother is a very pious word and whosoever is called by the name ‘Mother’ is a person who sacrifices and\\n            prioritizes her children over anything.',\n",
       " 'Her whole Life revolves around the well-being of her child, their growth, \\n            their development, and their welfare.',\n",
       " 'A Mother not just only gives birth to a child but she takes a Lifelong \\n            commitment to take care of her child.',\n",
       " \"The only unconditional love in the world is the mother's love.\",\n",
       " 'My mother is my inspiration, my superhero, my best \\n            friend, and my guiding light.',\n",
       " 'My life would not have been beautiful without my mother.',\n",
       " 'Through ups and downs and in\\n            every step of life, she holds my hand and supports and encourages me.',\n",
       " 'No matter what happens, my mother is always \\n            there beside me- cheering me up and motivating me.',\n",
       " \"All mothers in the world are great and so, we should not \\n            celebrate their contribution in our life on Mother's Day only, which is 10th May, but every day of the year and \\n            throughout their life.\",\n",
       " 'It is because no gesture of appreciation is ever enough when it comes to acknowledging our \\n            mother.',\n",
       " 'Her selfless love and sacrifice are the precious of all gifts under the sun.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c810b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28f1e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "result = tokenizer.tokenize(tokenize_para[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a6aa6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'only',\n",
       " 'unconditional',\n",
       " 'love',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'is',\n",
       " 'the',\n",
       " 'mother',\n",
       " 's',\n",
       " 'love']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3b56cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b21ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c9c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_para_word = word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8ac38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_para_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b6ec401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_para_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0cfcc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "updated_tokenized_para_word = tokenizer.tokenize(str(tokenized_para_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b42a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_tokenized_para_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e041a2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'word',\n",
       " 'Mother',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'pious',\n",
       " 'word',\n",
       " 'and',\n",
       " 'whosoever']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_tokenized_para_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "329ae191",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_token_list = [word for word in updated_tokenized_para_word if not word in removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "160be96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(modified_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19aeaa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'word',\n",
       " 'Mother',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'pious',\n",
       " 'word',\n",
       " 'and',\n",
       " 'whosoever']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_tokenized_para_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db31c4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'word',\n",
       " 'Mother',\n",
       " 'pious',\n",
       " 'word',\n",
       " 'whosoever',\n",
       " 'called',\n",
       " 'name',\n",
       " 'Mother',\n",
       " 'person']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_token_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ac3f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17f650b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38892859",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [stemmer.stem(i) for i in modified_token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "698c1f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'word',\n",
       " 'mother',\n",
       " 'piou',\n",
       " 'word',\n",
       " 'whosoev',\n",
       " 'call',\n",
       " 'name',\n",
       " 'mother',\n",
       " 'person']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e3ca090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b12084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_stem = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e338a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_stemmed_words = [lan_stem.stem(i) for i in modified_token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec9399ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'word',\n",
       " 'moth',\n",
       " 'pio',\n",
       " 'word',\n",
       " 'whosoev',\n",
       " 'cal',\n",
       " 'nam',\n",
       " 'moth',\n",
       " 'person']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lan_stemmed_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93c18f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'process'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"Processor\"\n",
    "lan_stem.stem(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63bb519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'processor'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74e3e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd2d084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95da2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_words = [lemm.lemmatize(i) for i in modified_token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "951f5bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'word',\n",
       " 'Mother',\n",
       " 'pious',\n",
       " 'word',\n",
       " 'whosoever',\n",
       " 'called',\n",
       " 'name',\n",
       " 'Mother',\n",
       " 'person']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66169272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " 'friend',\n",
       " 'guiding',\n",
       " 'light',\n",
       " 'My',\n",
       " 'life',\n",
       " 'would',\n",
       " 'beautiful',\n",
       " 'without',\n",
       " 'mother',\n",
       " 'Through']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_words[45:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9bb617e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " 'friend',\n",
       " 'guiding',\n",
       " 'light',\n",
       " 'My',\n",
       " 'life',\n",
       " 'would',\n",
       " 'beautiful',\n",
       " 'without',\n",
       " 'mother',\n",
       " 'Through']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_token_list[45:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b10c1ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m words \u001b[38;5;241m=\u001b[39m [word_tokenize(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sent_tokenize(paragraph)]\n\u001b[1;32m----> 2\u001b[0m pos_tags \u001b[38;5;241m=\u001b[39m [nltk\u001b[38;5;241m.\u001b[39mpos_tag(i, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniversal\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m words \u001b[38;5;241m=\u001b[39m [word_tokenize(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sent_tokenize(paragraph)]\n\u001b[1;32m----> 2\u001b[0m pos_tags \u001b[38;5;241m=\u001b[39m [nltk\u001b[38;5;241m.\u001b[39mpos_tag(i, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniversal\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "words = [word_tokenize(i) for i in sent_tokenize(paragraph)]\n",
    "pos_tags = [nltk.pos_tag(i, tagset=\"universal\") for i in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c03f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da28d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Cake is a form of sweet food made from flour, \n",
    "suger, and other ingredients, that is usually baked.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ddf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fae26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20475164",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_text = nltk.pos_tag(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa31b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = nltk.RegexpParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = phrases.parse(pos_tag_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4da66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27561631",
   "metadata": {},
   "outputs": [],
   "source": [
    "count-vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = count_vect.fit_transform(paragraph.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67870533",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bag_of_words.toarray(),columns=count_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d766c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc109dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = wordnet.synsets(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dac535",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn[0].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821bb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn[0].examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81711282",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f68da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn[4].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d68cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_syn = wardnet.synset(\"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f299b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eace51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_syn[3].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba910520",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bank_syn:\n",
    "    print(i.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_syn[6].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acace809",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_syn = wardnet.synsets(\"mouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603708d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The process of classifying words into their parts of speech and labelling them accordingly is known as part-of-speech tagging, POS-tagging, or simply tagging. \n",
    "Parts of speech are also known as word classes or lexical categories. \n",
    "The collection of tags used for a particular task is known as a tag set.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37916cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "freq_dist.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word_tokenize(i) for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ad7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd390c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3af04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
